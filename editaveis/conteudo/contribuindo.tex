\section{Contribuindo com plataformas abertas} % (fold)
\label{sec:contribuindo_com_plataformas_abertas}

Um dos objetivos deste trabalho era contribuir com uma aplicação \textit{open-souce} disponível na plataforma \href{http://github.com}{GitHub}\footnote{Disponível em \url{http://github.com}.}. Na próxima seção será apresentada a forma como tais contribuições foram realizadas. Devido ao fato do repositório do {\code APT} estar armazenado no GitHub, a terminologia apresentada estará em maior conformidade com esta plataforma, porém o conceito de \textit{pull-request} ou  \textit{merge-request} é amplamente utilizado em outras plataformas, como \href{https://bitbucket.org/}{Bitbucket}\footnote{Disponível em \url{https://bitbucket.org}.}, \href{https://gitlab.com/}{GitLab}\footnote{Disponível em \url{http://gitlab.com}.} ou até mesmo \href{http://sourceforge.net/}{SourceForge}\footnote{Disponível em \url{http://sourceforge.net}.}.


\subsection*{Mantendo uma copia} % (fold)
\label{sub:mantendo_uma_copia_sua}


Normalmente não temos autorização pra alterar as informações de outra pessoa sem seu consentimento. Da mesma forma  é com os repositórios {\code git}. Assim, um dos primeiros passos para começar a contribuir com uma ferramenta \textit{open-source} é fazer uma copia dela em seu repositório. Essa cópia pode ser feita de duas formas basicamente, no intuito de manter os autores das modificações anteriores:

\begin{description}
	\item [\textit{Fork}]: O termo é amplamente utilizado quando queremos fazer uma copia de um repositório para a nossa conta em uma mesma plataforma. Normalmente este passo é realizado via interface gráfica, ainda no navegador. Na \autoref{fig:github_fork} é possível observar o botão no canto superior direito indicado para realizar um \textit{fork} do atual repositório.

	\begin{figure}[h]
	  \centering
		\includegraphics[width=0.90\textwidth]{figuras/fork}
	  \caption{Visão de um repositório do \textit{GitHub}}
	  \label{fig:github_fork}
	\end{figure}

	\item [\textit{Adicionando \textit{remote}}]: Quando desejamos realizar uma copia do repositório em uma plataforma distinta da original, a forma mais simples de proceder é clonando o repositório e incluindo nele um novo \textit{remote} para a nova plataforma. Assim conseguimos trabalhar com a mesma arvore de \textit{commits} do repositório original, mantendo os créditos e alterações originais.
\end{description}
% subsection mantendo_uma_copia_sua (end)

\subsection*{Evoluindo o código} % (fold)
\label{sub:evoluindo_o_c_digo}

Nesto ponto de contribuição, o contribuinte desenvolve o código semelhante ao processo de produção de código pessoal. O código já esta em um repositório pessoal e o usuário já possui todos os direitos administrativos do repositório. Obviamente que caso a contribuição esteja sendo feita à uma aplicação grande e com muitos contribuidores, é importante se manter sincronizado com o código original, para evitar que o retorno da contribuição não seja tão trabalhoso para o revisor, além de evitar situações de conflitos.
% subsection evoluindo_o_c_digo (end)

\subsection*{Retornando sua contribuição} % (fold)
\label{sub:retornando_sua_contribui_o}

Quando se decidido que a contribuição já esta a um ponto aceitável para encaminha-la de volta para o código original, é o momento de se realizar o \textit{pull-request}\footnote{Ou \textit{merge-request} dependendo do ambiente de desenvolvimento em que esteja-se contribuindo.}. Uma contribuição é interessante quando possui as seguintes características:


\begin{itemize}
	\item Evolução de código mantendo os padrões de guia de estilo definido pelo desenvolvedor original/linguagem.
	\item Testes para a evolução de código proposto.
	\item Documentação da \textit{feature} implementada ou atualização da documentação como reflexão das modificações sugeridas.
\end{itemize}
% subsection retornando_sua_contribui_o (end)

Realizada a contribuição, é dever do mantenedor do repositório original revisar o código e decidir se deve ou não aceita-lo.


\subsection*{Testando} % (fold)
\label{sub:testando}

É como em desenvolvimento de software haver ao menos testes unitários a cada evolução de código, a fim de validar a funcionalidade. No projeto abordado neste trabalho em especial há testes utilizado o \href{https://github.com/google/googletest}{Google C++ Testing Framework}\footnote{Disponível em \url{https://github.com/google/googletest}.} (Google Test), um \textit{framework} desenvolvido pela Google para testes. Ele tem suporte para um conjunto de assertivas pre-definidas e definidas pelo usuário, tornando-se uma das melhores ferramentas para a escrita de \textit{suite} de testes para C/C++ hoje disponíveis.

Outra categoria de testes bastante usuais são os testes de integração. Neste trabalho em especial estará sendo utilizado um \textit{script shell} que oferece diversas funcionalidades para a criação dos testes de integração. Os testes de integração são utilizados no {\code APT} como testes caixa preta, a fim de verificar a funcionalidade de cenários de testes.

Os testes de integração são mais priorizados que os unitários no APT, e podemos observar isso pela quantidade de casos de testes em cada um deles. Nos testes unitários temos 20 casos de testes, totalizando um total de 78 testes unitários. Já na integração temos um conjunto de 199 cenários de testes com um total de 24.976 testes de integração\footnote{Dados relativos a \textit{build} \#219 do \href{https://travis-ci.org/Debian/apt/builds/}{Travis-CI}, disponível em \url{https://travis-ci.org/Debian/apt/builds/}.}.


\begin{lstlisting}[language=C++,label=gtestexample,caption={Teste de validação de armazenamento de parâmetros}]
TEST(CommandLineTest,SaveInConfig)
{
   EXPECT_CMD("apt-get install -sf",
	 "apt-get", "install", "-sf");
   EXPECT_CMD("apt-cache -s apt -so Debug::test=Test",
	 "apt-cache", "-s", "apt", "-so", "Debug::test=Test");
   EXPECT_CMD("apt-cache -s apt -so Debug::test=\"Das ist ein Test\"",
	 "apt-cache", "-s", "apt", "-so", "Debug::test=Das ist ein Test");
   EXPECT_CMD("apt-cache -s apt --hallo test=1.0",
	 "apt-cache", "-s", "apt", "--hallo", "test=1.0");
}
\end{lstlisting}

Um exemplo de teste unitário realizados é a validação do armazenamento dos parâmetros nas chamadas, como pode ser observado no \autoref{gtestexample}. Já testes de integração possuem um comparativo entre uma chamada e sua saída, como pode ser observado no \autoref{integrationtesteexample}.

\begin{lstlisting}[language=Bash,label=integrationtesteexample,caption={Teste de verificação de saída para busca}]
# without op progress
testsuccessequal "foo/unstable 1.0 all
  $DESCR
" apt search -qq xxyyzz
\end{lstlisting}

% subsection testando (end)
% section contribuindo_com_plataformas_abertas (end)


\section{Coleta de Dados} % (fold)
\label{cha:coleta_de_dados}

\subsection*{Tempo} % (fold)
\label{sec:tempo}

A coleta de tempo de performance de um software é árdua. A estimativa de tempo depende das otimizações que o compilador pode vir a fazer para a arquitetura, memoria disponível, aplicativos rodando em concorrência, temperatura do hardware, etc. No intuito de simplificar o processo de estimativa de tempo, foi utilizado a mediana de uma serie de chamadas da aplicação. Segundo \citeonline{dolan2002benchmarking}, esta solução pode vir ser a melhor para um ponto geral de $25\%$ das possíveis alternativas de coletas de dados. Assim sendo, o \autoref{scriptods} foi uma solução desenvolvida que permitisse deixar a maquina com tempo dedicado para a aquisição de dados.

Para o funcionamento do \textit{script}, as variáveis {\code MAX} e {\code \_MAX\_THREADS} devem ser definidas com a quantidade de dados que se deseja coletar e a quantidade máxima de \textit{threads} que devem ser levantadas para a chamada do processo respectivamente. Usar uma quantidade superior a quantidade de \textit{cores}  da maquina pode produzir valores com baixa confiabilidade, visto a concorrência gerada pelas \textit{threads}. Como parâmetros, foram escolhidos $150$ dados com $7$ \textit{threads}, possibilitando haver ao menos $1$ \textit{core} livre. Para maior dinamismo da coleta dos dados, o \textit{script} é responsável por realizar a troca das \textit{branchs} onde estão localizadas as possíveis soluções e a compilação e concentração dos dados em uma planilha do \textit{LibreOffice Calc}. Assim, os algoritmos nunca são executados em concorrência, porém os dados serão coletado sob a demanda da $CPU$ em que o \textit{script} é executado.

No intuito de coletar o tempo pontual do algoritmo, o \autoref{libtime} foi desenvolvido a fim de ser usado como cronometro. O algoritmo desenvolvido com o auxilio da biblioteca {\code Chrono}\footnote{A biblioteca é disponibilizada no {\code C++11} sob o \textit{namespace} {\code std::crono::}.} permite a captura do intervalo de tempo com ate $9$ casas decimais de segundos (nanosegundos), todavia foi utilizado a precisão de microssegundos apenas, visto que o intervalo de nanosegundos não iria gerar alto impacto na diferença dos valores. Os métodos {\code begin} e {\code end} da classe são utilizados para pontuar os intervalos onde o tempo deve ser contado. O resultado da contagem pode ser obtido com o retorno do método {\code end} ou com a chamada do {\code currenttime}, dedicado apenas para o retorno deste valor.

\subsection*{Memória}

Para a coleta de memória, foi utilizado o {\code Valgrind} com o auxilio da ferramenta {\code Massif}. Devido a haver uma criação de \textit{hash} de forma  algébrica e o método de \textit{KMP} faz uso de um autômato finito determinístico, a previa repetição das buscas com apenas $10$ ciclos confirmavam a suspeita de não haver a variação do gasto de memória para a repetição da ação.

Para a execução da aplicação com o suporte do {\code Valgrind} para analise do uso de memória, foi utilizado o seguinte comando:

\begin{lstlisting}[language=Bash,label=valgrind_call, numbers=none]
   $ valgrind --tool=massif  ./apt search pacote [--regex]
\end{lstlisting}
% section tempo (end)
% chapter coleta_de_dados (end)


\section{Primeira contribuição} % (fold)
\label{sec:primeira_contribui_o}

A primeira contribuição tinha como objetivos a ambientalização com o ambiente e o time oficial de desenvolvimento. Como tarefa, foi definido a implementação minima de uma estrutura que permita um contexto de ordenação que possa ser definido pelo usuário. O intuito era oferecer as seguintes opções de ordenação na primeira contribuição:

\begin{description}
	\item [\textit{Alphabetic}] Ordenação padrão em ordem alfabética. Os pacotes são ordenados de acordo com seu nome.
	\item [\textit{Reverse Alphabetic}] Semelhante a ordenação alfabética, porém em ordem decrescente, ou seja, palavras que começam com {\code Z} são apresentadas antes das iniciadas com {\code A}.
	\item [\textit{Status}] Ordena os pacotes de acordo com as seguintes características:
	\begin{enumerate}
		\item Desinstalado,
		\item Instalado e com possível atualização,
		\item Instalado via pacote local,
		\item Instalado e descartável (auto removível),
		\item Instalado automaticamente,
		\item Instalado,
		\item Atualizável,
		\item Com configuração residual
	\end{enumerate}
	\item [\textit{Version}] Ordena a saída de acordo com a versão da aplicação.
\end{description}

\subsection*{Alteração da estrutura de dados} % (fold)
\label{sub:altera_o_da_estrutuda_de_dados}

Originalmente, os dados eram armazenados em um {\code map}, visto que essa estrutura não permite a duplicação de chaves e possui uma ordenação alfabética automática. Todavia, alterar o algoritmo de ordenação de um {\code map} ocorrem em seu tempo de declaração, o que  inviabiliza a possibilidade de alterar a ordenação através de uma \textit{flag} como parâmetro de execução. Visto essa condição, a estrutura foi alterada para a estrutura de dados {\code vector}, por ser mais flexiva quanto a sua forma de ordenação.

Naturalmente, a inserção de candidatos na saída do {\code APT} ocorre  em dois níveis. O primeiro ordena de acordo com os repositórios inseridos no {\code source.list} da distribuição. Candidatos de um mesmo repositório serão naturalmente ordenados alfabeticamente. Isso implica que apenas adicionar candidatos no vetor implicaria em uma ordenação com baixa precisão, visto que a sequência de repositórios variaria de usuário para usuário. Assim, a simples troca de estrutura de dados de {\code map} para {\code vector} implica na necessidade de implementar o método de ordenação alfabética, antes nativamente implementado pela estrutura {\code map}.

Tendo um método para ordenação alfabética simplifica o processo de ordenação alfabético reverso, visto que basta enviar as referências do vetor com suas reversas, ao invez da normais. Assim, bastando ser necessário a escrita de três métodos no total para a primeira contribuição. No trecho de código a seguir é apresentado como a seleção de ordenação é tomada.


\begin{lstlisting}[language=C++,label=choose_pr1,caption={Tomada de decisão de ordenação}]
   switch(PackageInfo::getOrderByOption())
   {
      case PackageInfo::REVERSEALPHABETIC:
		 std::sort(outputVector.rbegin(), outputVector.rend(), OrderByAlphabetic);
		 break;
      case PackageInfo::STATUS:
			 std::sort(outputVector.begin(), outputVector.end(), OrderByStatus);
			 break;
      case PackageInfo::VERSION:
		 std::sort(outputVector.begin(), outputVector.end(), OrderByVersion);
		 break;
      default:
		 std::sort(outputVector.begin(), outputVector.end(),   OrderByAlphabetic);
		 break;
   }
\end{lstlisting}

A versão apresentada neste trabalho é o resultado de alguns \textit{feedback} sugeridos pelos mantenedores do projeto, em especial \href{https://github.com/DonKult}{David Kalnischkies}, o qual fez questão de pontuar detalhes na contribuição que poderiam ser melhorados ou questionados\footnote{David Kalnischkies não via muito sentido em uma ordenação por \textit{status}, porém não vetou a contribuição, visto que este pedido havia sido feito pelo membro \href{https://github.com/mvo5}{Michael Vogt} nos comentários da versão original do código.} no processo de aceitação da contribuição.

% subsection altera_o_da_estrutuda_de_dados (end)

\subsection*{Testando alterações} % (fold)

Realizar uma contribuição sem seus testes implica em oferecer um trabalho sem garantias de funcionalidade. Desta forma, as contribuições realizadas neste trabalho também estão sempre acompanhadas de seus respectivos testes. O {\code APT} utiliza uma ferramenta de testes muito comum em $C++$, a \textit{Google Test}\footnote{Mais informações sobre a ferramenta podem ser obtidas em seu repositório oficial: \url{https://github.com/google/googletest}.}. Uma \textit{suite} de testes é caracterizada pelo \textit{Google Test} como um arquivo contendo $n$ testes. Para manter o contexto, as condições da \textit{suite} de testes deve ser definida no inicio.

\begin{lstlisting}[language=Bash,label=googletest_decl,caption={Declarações de instâncias para o teste}]
setupenvironment
configarchitecture "i386"

DESCR='Some description that has a unusual word xxyyzz and aabbcc and a UPPERCASE'
DESCR2='Some other description with the unusual aabbcc only'
DESCR3='Some package description'
DESCR4='an autogenerated dummy baz=0.1/installed'
insertpackage 'unstable' 'foo' 'all' '1.0' '' '' "$DESCR
 Long description of stuff and such, with lines
 .
 and paragraphs and everything."
insertpackage 'testing' 'bar' 'i386' '2.0' '' '' "$DESCR2"
insertpackage 'stable' 'package' 'all' '1.5' '' '' "$DESCR3"
insertinstalledpackage 'baz' 'all' '0.1'

setupaptarchive
\end{lstlisting}

Como apresentado no \autoref{googletest_decl}, algumas macros foram criadas pela equipe do {\code APT} para simplificar o processo de declaração de instâncias. Com estas instâncias declaradas, o contexto do teste é estabelecido e esta pronto para a \textit{suite} de testes rodarem. Os testes são basicamente cenários do estado do sistema, como pode ser observado no \autoref{gtest_foo}.

\begin{lstlisting}[language=Bash,label=gtest_foo,caption={Teste por busca pelo pacote \textit{foo}}]
# search name
testsuccessequal "foo/unstable 1.0 all
  $DESCR
" apt search -qq foo
\end{lstlisting}

Como estamos fazendo ordenação de pacotes, é importante que se possa realizar uma busca por uma grande quantidade de pacotes. Uma das possibilidades que o {\code APT} possui hoje é a de se realizar buscas utilizando de expressões regulares. Unindo esta duas características, podemos montar uma lista maior de pacotes e realizar uma busca por um termo genérico, a fim de obter como resultado toda a lista de pacotes. O exemplo o \autoref{buscacomregex} demostra este resultado, onde a busca é feita utilizando a \textit{regex} {\code \textbackslash w}, a fim de selecionar todos os pacotes que possuam ao menos um caractere no nome.

\begin{lstlisting}[language=Bash,label=buscacomregex,caption={Busca com uso de expressão regular}]
# output is sorted by status
testsuccessequal "bar/testing 2.0 i386
  $DESCR2

foo/unstable 1.0 all
  $DESCR

package/stable 1.5 all
  $DESCR3

baz/now 0.1 all [installed,local]
  $DESCR4
" apt search --order-by status -qq "\\w"
\end{lstlisting}

\begin{figure}[h]
  \centering
	\includegraphics[width=0.75\textwidth]{figuras/pr1}
  \caption{Submissão do primeiro \textit{merge request}}
  \label{fig:pr1_travisnotok}
\end{figure}

A \autoref{fig:pr1_travisnotok} apresenta o resultado do \textit{merge request} e alguns dos commits enviados, sendo o ultimo deles com o resultado do \textit{Travis CI} apontando falha na \textit{build} devido à falha em um dos testes de integração que verificam concorrência de download de arquivos.

% section primeira_contribui_o (end)


\section{Segunda contribuição} % (fold)
\label{sec:segunda_contribui_o}

O suporte a expressões regulares amplia como a busca por pacotes pode ser efetuada, possibilitando uma maior gama de ferramentas para desenvolvedores experientes. Todavia, deixar essa opção como padrão acarretam em alguns pontos negativos que são desempenhados todas as vezes que a aplicação é executada:

\begin{description}
	\item [Alto consumo de memoria:] Buscas com expressões regulares consomem cerca de $\Theta(2^n)$ para uma expressão de tamanho $n$, ou $\Theta(n^2)$ para melhores casos, com hardware dedicado \cite{sidhu2001fast}.
	\item [Baixo desempenho:] Buscas com expressões regulares tem custo de desempenho $\Theta(n)$, sendo $n$ o tamanho da palavra a ser analisada.
\end{description}

Mesmo a busca com expressões regulares oferecendo um grande poder de busca, questiona-se se o custo que ela requer é interessante. Lembrando que este trabalho visa ampliar a comodidade daqueles novos usuário ao mundo Linux, as funções de expressões regulares normalmente não são de conhecimento do usuário leigo. Considerando que este usuário leigo não irá fazer comumente das funções {\code less}, {\code more} ou {\code grep} para auxiliar com buscas, será de menor representatividade então o uso de expressões regulares.

% Ora, se há a possibilidade de ganhar desempenho e gasto de memoria mesmo ainda com busca exatas, há de se propor algoritmos para nos auxiliar com essas buscas.


Visando uma alternativa para a busca de pacotes que ofereça menor tempo de processamento e maior economia de memoria, foram estudados dois algoritmos de \textit{string matching} exato abordados inicialmente neste trabalho na \autoref{sec:algoritimos_de_textit}, são os modelos de \nameref{ssub:rabin_karp} e \nameref{ssub:knuth_morris_pratt_}. Para ambos os modelos foram criadas \textit{branchs} para seu desenvolvimento e testes de desempenho, fazendo de uso da rotina apresentada no \autoref{libtime} para mensurar o tempo gasto para formular a resposta da pesquisa. 

Diante dos resultados de tempo obtidos com o algoritmo de \textit{Rabin-Karp}, a segunda contribuição foi planejada e executada. A \autoref{sec:segundo_pr} apresenta na integra o \textit{diff} da contribuição submetida para o repositório oficial.


A fim de manter a cobertura das funcionalidades, testes foram feitos para garantir que as buscas continuavam a ser realizadas com ou sem o uso da \textit{flag} que habilitava o uso de expressões regulares, como pode ser observado no \autoref{regextestscli}, onde um trecho dos testes da segunda submissão é apresentado.

\begin{lstlisting}[language=Bash,label=regextestscli,caption={Teste com e sem o uso de expressões regulares}]
# output is sorted by status
testequal "bar/testing 2.0 i386
  $DESCR2

foo/unstable 1.0 all
  $DESCR

package/stable 1.5 all
  $DESCR3

baz/now 0.1 all [installed,local]
  $DESCR4
" apt search --order-by status -qq "\\w" --regex

# output is sorted by Alphabetic (non case sense)
testequal "bar/testing 2.0 i386
  $DESCR2

baz/now 0.1 all [installed,local]
  $DESCR4
" apt search --order-by Alphabetic -qq ba
\end{lstlisting}

Garantido haver testes e documentação que validem as implementações, foi realizado a submissão de \textit{merge request} ao repositório oficial do APT, a qual pode ser observada na \autoref{fig:pr2_travisok} e acompanhada em \url{https://github.com/Debian/apt/pull/8}.

\begin{figure}[h]
  \centering
	\includegraphics[width=0.95\textwidth]{figuras/pr2}
  \caption{Submissão do segundo \textit{merge request}}
  \label{fig:pr2_travisok}
\end{figure}

% section segunda_contribui_o (end)

\section{Terceira contribuição} % (fold)
\label{sec:terceira_contribui_o}

Por fim chegamos ao ponto desejado para este trabalho, oferecer uma ferramenta de busca de pacotes o mais transparente possível quanto ao método de busca. Para tal precisamos ainda realizar duas tarefas:

\begin{description}
	\item [Escolha inteligente entre expressões regulares ou busca padrão:] Mesmo oferecendo uma \textit{flag} para selecionar a busca com suporte a expressões regulares, é importante deixar que o programa seja capaz de identificar quando uma \textit{flag} é passada para que a busca seja realizada corretamente.
	\item [Inserir método de buscas inexatas:] Quando uma busca não obtiver nenhum resultado, a aplicação deve executar a busca novamente com o método de buscas inexatas e apontar os pacotes que poderiam se encaixar com a busca realizada.
\end{description}

Para realizar a primeira tarefa devemos primeiro implementar uma função que verifique se entre os parâmetros passados na busca há um caractere especial utilizado para expressões regulares. Estes caracteres deveriam de ser {\code |\textbackslash\{\}[]():*+-\$?.\^{}}, porém os caracteres {\code .}, {\code :} e {\code -} costumam aparecer nos nomes dos pacotes e assim devem ser ignoradas como sinais que indicam uso de expressões regulares.

\begin{lstlisting}[language=C++,label=regexidentify,caption={Identificação de Expressões Regulares}]
bool identify_regex(std::vector<std::string> input)
{
   /*
      not all characters can be included, as have
      packages with the chars .-:
   */
   std::string reserver_regex = "^$*+?()[]{}\\|";

   for(auto k:input)
      if( reserver_regex.find(k) == std::string::npos )
	 return true;
   return false;

}
\end{lstlisting}

O \autoref{regexidentify} apresenta uma solução para a identificação de caracteres que indicam o uso de expressões regulares nas buscas, verificando cada palavra em uma lista de \textit{strings} em busca dos caracteres que identificariam uma expressão regular. Caso algum caractere especial seja localizado, a função retorna verdadeiro.


Em seguida, verificamos se é utilizado a \textit{flag} de uso de expressão regular ou caracteres reservados com a seguinte verificação:

\begin{lstlisting}[language=C++,basicstyle=\footnotesize\ttfamily,numbers=none]
if ((_config->FindB("APT::Cache::UsingRegex",false)) || identify_regex(args))
\end{lstlisting}

Caso a chamada acima seja verdadeira, as rotinas que compilam as expressões regulares serão executadas, caso contrario, o método de \nameref{ssub:rabin_karp} será executado para realizar a busca, visto este método ter apresentado melhor desempenho frente ao método de \nameref{ssub:knuth_morris_pratt_}, como será melhor apresentando em \lnameref{part:resultados} na \autoref{sec:algor_timos_de_string_matching_exatos}.


Realizado esta etapa, o próximo, e ultimo, passo é identificar buscas onde nenhum pacote é localizado. Nestes casos, o modelo de \textit{\nameref{sec:leveinstein}} deve ser utilizado para encontrar os pacotes que contenham a menor diferença com a pesquisa realizada. Essa chamada deve ser realizada somente caso não haja o uso de caracteres que identifiquem o uso de expressões regulares, visto ser uma busca que requer um tempo maior e que será executada após uma busca já ter sido realizada.

Para realizar a busca utilizando o modelo de \textit{Leveinstein} é necessário percorrer a lista de pacotes duas vezes. Na primeira vez é pontuado a distância do nome do pacote com os parâmetros de entrada da busca e na segunda vez os pacotes são ordenados de acordo com sua pontuação. O \autoref{levisearchapt} apresenta a realização desta busca, percorrendo toda a lista de pacotes, {\code bag}, disponível e em seguida ordenando a saída.

\begin{lstlisting}[language=C++,label=levisearchapt,caption={Busca ordenada por distância de \textit{Levenshtein}}]
for(auto V:bag)
{

	// we want to list each package only once
	pkgCache::PkgIterator const P = V.ParentPkg();
	if (PkgsDone[P->ID] == true)
		continue;

	std::string PkgName = P.Name();
	pkgCache::DescIterator Desc = V.TranslatedDescription();
	pkgRecords::Parser &parser = records.Lookup(Desc.FileList());
	std::string const LongDesc = parser.LongDesc();

	for (auto arg:args)
	{
		int distance = levenshtein_distance(PkgName, arg);
		if ((distance >=0) && (distance <= (int)PkgName.length()/2 ))
		{
			PkgsDone[P->ID] = true;
			std::stringstream outs;
			ListSingleVersion(CacheFile, records, V, outs, format);
			outputVector.emplace_back(CacheFile, records, V, outs.str());
			outputVector.back().distance = distance;
		}
	}
}
std::sort(outputVector.begin(), outputVector.end(), OrderByDistance);
\end{lstlisting}

Devido a buscas inexatas consumirem mais recursos e necessitarem de passar por todo o vetor novamente, elas foram deixadas para executar apenas quando a busca não tivesse nenhum resultado. O \autoref{calllevisearchapt} apresenta a chamada quando esta situação correr.

\begin{lstlisting}[language=C++,label=calllevisearchapt,caption={Chamada seletiva para buscas inexatas}]
if(outputVector.size() == 0)
{
	outputVector = SimilarSearch(bag,args);
	if(outputVector.size() > 10)
	outputVector.resize(10);
	std::cout << "None package fould. Maybe you are looking for one of those:" << std::endl;
}
\end{lstlisting}


Para a realização desta contribuição, foi aproveitada a comtribuição anterior, apenas atualizando a \textit{branch} de contribuição com os novos \textit{commits}. Na \autoref{fig:pr3_travisok} podemos observar o mesmo \textit{merge request} requisitado para a segunda contribuição agora com o acréscimo do \textit{commit} {\code aae1adc}, onde todas as contribuições do terceiro grupo de contribuições deste trabalho foram juntadas para simplificar a visualização e revisão do \textit{merge request}.

\begin{figure}[h]
  \centering
	\includegraphics[width=0.95\textwidth]{figuras/pr3}
  \caption{Submissão do segundo \textit{merge request} atualziada com o conteudo da terceira contribuição}
  \label{fig:pr3_travisok}
\end{figure}
% section terceira_contribui_o (end)
